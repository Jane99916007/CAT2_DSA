                     Big-O-Notation
## Definition
It describes the upper bound of an algorithm's time complexity as the input size increases.

## Its complexities
O(1)- Constant time: They require the same amount of time regardless of the size of input e.g.,accessing an array element.

O(n)- Linear time: The execution time grows directly proportional to the logarithm of the input size e.g.,transversing an array.

O(log n)-Logarithmic time: Operations that involve continually dividing the input size e.g.,Binary search.

O(n²)- Quadratic time: Time rises proportionately to the square of the input size as is often seen in algorithms with nested loops e.g.,Bubble sort.

O(n log n)- Log linear time: It combines linear and logarithmic growth which is frequently used inefficient sorting algorithms.

O(2ⁿ)- Exponential time: The runtime grows exponentially with the size of the input hence makes the method slow for large inputs.

O(n!)-Factorial time: The runtime grows quickly with the input size making these methods not feasible for all but the smallest inputs.

## Rules for analyzing algorithms with Big O Notation

#### Emphasis on Worst-Case Scenario
Big O notation indicates the maximum amount of time an algorithm could take to execute, independent of the input.

#### Ignore Constant Factors
Constants are left out since they have no bearing on the total growth rate. O(2n) for instance, simplifies to O(n).

##### Determine which term is Dominant
If there are several terms, concentrate on the one that expands the fastest as the size of the input rises.

##### Asymptomatic Analysis
Rather than focusing on the precise execution time for tiny inputs, Big O notation examines how an algorithm performs as the input size gets closer to infinity.


